# AI Code Review Policy Rules
# This file contains human-readable rules for evaluating code in repositories and pull requests

## High AI Confidence
When code appears to be AI-generated with high confidence (over 80%), we need to ensure proper attribution. 
This level of AI probability strongly suggests that the code was generated by an AI tool.
If we detect this pattern, flag this as an error and require proper attribution or license information.

## Medium AI Confidence
When code shows medium confidence of being AI-generated (60-80%) and there's no license or attribution,
we should request proper documentation. This level of AI probability suggests significant portions may be AI-generated.
Flag this as an error if no license comment is found.

## Likely AI Generated
When code shows some signs of being AI-generated (40-60%) but lacks proper attribution, 
we should suggest adding appropriate documentation. This level indicates the code may contain AI-generated portions.
This is a warning that should be addressed.

## Poor Comment Quality
When code appears to be AI-generated, we often see high-quality comments that focus more on explaining what the code does
rather than why certain decisions were made. Good comments should focus on the reasoning and context behind implementations,
not just restating the code. Look for this pattern in AI-generated code.

## Grammar Issues
High-quality grammar and perfect English throughout comments is a potential indicator of AI-generated code.
Human developers typically make typos, use shorthand, and write in a more casual style. Watch for unnaturally 
perfect grammar as a sign of AI generation.

## Missing Context
When substantial code is added without sufficient high-level documentation explaining the purpose, architecture,
and design decisions, it may indicate AI-generated code that lacks proper context. Look for missing explanations
of "why" certain approaches were chosen.

## Missing Tests
If substantial code appears to be AI-generated but no test files were modified, this suggests the changes
weren't developed using test-driven practices. AI often generates implementation without corresponding tests.
Request appropriate test coverage for potentially AI-generated code.

## Excessive Code
Large code submissions that appear to be AI-generated should be broken into smaller, more focused pull requests.
This allows for better review and understanding of the changes. Watch for large dumps of code that show
AI-generation patterns.
